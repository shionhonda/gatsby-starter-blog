---
title: 忙しい人のためのTuning Playbook
date: "2023-01-26T23:02:03.284Z"
description: "妻と続けているクリスマスの習慣「プレゼントは本にして、残った予算で寄付をする」を紹介します。"
featuredImage: tuning_playbook/ogp.jpg
tags: ["ja", "deep-learning"]
---

Tuning Playbookが公開された
https://github.com/google-research/tuning_playbook
素晴らしいものだが、例えば同僚に気軽に薦めるには長すぎる。学習も兼ねて日本語で要点をまとめた。

論文には「綺麗にされた」結果しか書かれていないが、実際には経験的に決めなければならないハイパラがたくさんある。深層学習の達人とそうでない人の間には、暗黙の知見の差が存在する。これをまとめたドキュメントを作りたい。
このドキュメントは固定化されたものではなく、常にアップデートされるものであるべき。最適解ではないかもしれないが、たたき台としては十分に役立つはずである。理論付けがなされていないものは、良い研究テーマになるかも。

# 新しいプロジェクトを始めるときのガイド
この節では以下を仮定します：
- 問題設定やデータクリーニングは完了している
- 問題に即した適切な評価指標が選択できている
- 訓練と評価のパイプラインはできている

1. よく使われるモデルアーキテクチャと最適化器を選ぶ
2. メモリが許す最大のバッチサイズを選ぶ
3. ハイパーパラメータを決める

## モデルアーキテクチャ
*既にうまくいくことがわかっているモデルから始めましょう。*
- ベースラインによく使われる、「枯れた」モデルを使いましょう
- 可能であれば類似した問題設定の論文を見つけて、それを再現実装してみましょう

## 最適化器
*その問題設定でよく使われる最適化器から始めましょう*
- あらゆる問題に使える「最強の」最適化器はありません
  - そもそも、最適化器の性能を比較すること自体が難しい問題です
- その問題設定でよく使われる最適化器から始めましょう
  - 例：SGD（モメンタム付き）、Adam、NAdam
- 最適化器のすべてのハイパーパラメータに注意を払いましょう
  - チューニングは後段で行うので、ここでは頭の片隅に入れておくだけで構いません
  - 悪い例：モデルの最適な層数を決めるときに、最適化器のハイパーパラメータをどの層数でも同じにする

## バッチサイズ
*バッチサイズは訓練が進む速度を定めるハイパーパラメータであり、検証セットでの性能によって直接チューニングすべきではありません。メモリに収まる最大値で固定しておくのがよいでしょう。*
- バッチサイズをなるべく大きく取ることで、訓練にかかる時間を最小化できます
  - 「訓練にかかる時間」は「1ステップあたりの時間」×「収束までのステップ数」です
  - 前者は、理想的にはバッチサイズによらず一定です
  - 後者は、バッチサイズと概ね反比例します
    - バッチサイズを2倍にすると、収束までのステップ数が半分になることが期待できますが、この効果はバッチサイズに対して逓減していきます
  - したがって、バッチサイズを大きく取るほど、訓練にかかる時間は短くなります
- バッチサイズを検証セットでの性能によって直接チューニングすべきではありません
  - 他のハイパーパラメータ（学習率やステップ数）を適切に選べば、任意のバッチサイズで同じ結果を達成できるはずです
- バッチサイズを決めるには、何度か訓練を実行してみる必要があります
  - OOMになるまでバッチサイズを2倍にし続けます
    - この間、1ステップあたりの時間は変わらないはずです
    - もし増えるのであれば、IOやノード間の同期などにボトルネックが存在しているので、先に進む前に解消しましょう
  - OOMになる直前のバッチサイズを選び、その値で固定します
  - 1ステップあたりの時間が一定のバッチサイズから増えるのであれば、そこで止めます
    - バッチサイズを大きくする目的は時間短縮だからです
    - 同様に、勾配累積（gradient accumulation）は時間がかかるので避けましょう
- モデルや最適化器によって許容できるバッチサイズが変わるので、これらを変更したらバッチサイズを決め直す必要があります
- 他のハイパーパラメータ、特に最適化器（学習率やモメンタム）と正則化はすべてバッチサイズに依存するので、バッチサイズは最初に決定しましょう
  - もし変更した場合は再度チューニングが必要です

## 初期設定
*初期段階のハイパーパラメータは、「そこそこの結果」にミニマルな実装で到達するという方針で決定しましょう。*
- 初期段階で定めなければならないハイパーパラメータは以下の3種類です
  - モデルに関するもの
    - 例：層数
  - 最適化器に関するもの
    - 例：学習率
  - 訓練ステップ数
- 初期段階では、「そこそこの結果」にミニマルな実装で到達することを目指します
  - 例：小さいモデル
  - 例：一定の学習率
- 訓練ステップ数は、性能と改善サイクルの短さのバランスから決めます

# 性能改善のためのアプローチ
仮定すること
- 訓練パイプラインとベースラインの初期設定ができている
- 実験を並列で回すだけの計算リソースがある
 
## incremental tuning
シンプルなベースラインから始めて、少しずつ改善を入れていく。不必要に複雑にしないため、強い根拠がない限り変更を加えないようにする
1. 次の実験のゴールを決める
2. ゴールを達成するための実験をデザインし、実施する
3. 結果から知見を得る
4. 新しいモデルをデプロイするかどうか決定する

以降ではこの戦略について詳しく見ていく

## 探索と活用のトレードオフ
多くの場合、ゴールは問題に関するインサイトを得ることである（活用フェーズには重きを置かない）
- インサイトを重視するほうが長期的には良いことが多い
  - ノイズに惑わされない
  - 重要なハイパラとそうでないハイパラを定めて、後者は固定してしまう
- 探索空間を十分に狭めることができたら、活用フェーズに入ってもよい


## 次の目標の定め方
各実験は明確な目的を持つべき。同時に複数のことをやろうとしない。
- 例
  - 新しい正則化を試す
  - 活性化関数の選び方が与える影響を調べる
  - 検証スコアを最大化する（活用）

## 次の実験の設計
ハイパラを3種類に分け、nuisanceで最適化した上でscientificを比較する。そのような実験を設計する。
- ハイパラは3種類に分けられる
  - scientific: モデルに与える影響に関心があるハイパラ
  - nuisance: scientificを比較するためにチューニングする必要があるもの（局外パラメータ）
  - fixed: 固定すべきもの。これを変えると、実験から得られるインサイトは成立しなくなる
- 例えば、層数が性能に与える影響を調べたいなら、層数、学習率、活性化関数がこれらに分類され得る
- これらは実験の目的によって変わる
　　- 最初にscientificを決め、次にリソース制約の元でnuisanceを決める。残りがfixed
　　- 最適化器のハイパラは大抵nuisance。最適化器の選択は、scientificかfixed
　　- 最適化器によっては新たなハイパラを導入することになる。これは大抵nuisance
- ハイパラを分類したら、nuisanceを最適化しつつscientific を比較する
  - ベイズ最適化を使ってもいいが、探索フェーズではquasi-randamな方法がおすすめ
- リソース制約のためにscientificを独立に実験できない場合はやむを得ず混ぜて実験する。その場合は特にquasi-randomな方法で一様にサンプリングすべき


## 実験結果から何を学ぶか
元のゴールを達成するだけでなく、チェックリストを見て、問題が見つかったら再実験をするべき
- チェックリスト（結論を導く前に確認する）
  - 探索空間は十分に大きかったか？
    - 最適解が境界付近にあったらダメ
    - 不足があれば探索を続ける
  - 探索空間から十分にサンプルしたか？（判定が難しい）
    - 不足があれば探索を続ける
  - 失敗する試行が多数あったか？
    - そうであれば探索空間を再設計すべき
  - 訓練カーブ
    - 検証誤差だけに集約してしまうと大事な情報を見落としてしまうかも
    - 最善の数試行だけでも、訓練カーブを見るようにする
    - 過学習しているようなら、次の実験に行く前に正則化（ドロップアウト、ラベル平滑化、重み減衰）を足して再試行してみる
    - 訓練の後半で訓練誤差や検証誤差がステップごとに振動していると正しい比較ができない
      - バッチサイズを上げる、検証データを増やす、LRを下げる、Polyak平均など
  - ハイパラを軸にとってプロットすると良い
  - 上記の手続きは自動化しよう

## 訓練パイプラインやハイパラの変更を採用するかどうかの意思決定
変動に注意しよう
- 良いスコアを出しているように見えた設定が再現できないことはある。その理由はインフォーマルには3つに分類できる
  - 訓練手順、再訓練、試行による分散：重みの初期値、データシャッフル、データ拡張、ドロップアウトなどの乱数シード
  - ハイパラ探索：ハイパラ探索の乱数シード
  - データ作成：データ分割の乱数シード
- 1つ目の試行ごとのばらつきが特に厄介なので、N回試すと良い
- 確実な答えは出せないので、最終的には複雑さとのトレードオフから判断することになる

## 探索が終わったら
探索空間が決まったら、ベイズ最適化が便利
- どこかで、チューニングの問題から最高スコアを出す問題にシフトする
- ここからはベイズ最適化が強力なツール
- ここまでできたらテストセットで試してみる

# 訓練ステップ数の決め方
compute-bound: 訓練すればするだけロスが下がる
## 計算量バウンドでない場合（途中で過学習する）
- 学習が終わってから最適なチェックポイントを選べばいい
- 長くしすぎると計算が無駄にはなるが、悪影響はない
- データ拡張やドロップアウトを追加した場合、勾配の分散が増えるので、ステップ数を増やすべき
## 計算量バウンドの場合（いくらでもロスが下がる）
- 途中で止めて良し悪しを判断することはある程度可能だが、間違えるリスクはある。試行回数とのトレードオフ
- 2ラウンドでチューニングする
  - モデルと最適化器のハイパラを決める、短いランをたくさん打つ
    - ここで決めたwarmup lengthや初期化、（モデルアーキテクチャ）は次のラウンドでも有効なことが多い
    - 最適化器の選択やハイパラ、データ拡張、正則化は有効かもしれない
    - 学習率のスケジュールはおそらく有効でない
  - 学習率スケジュール
    - よくわからん

# その他
## 入力パイプラインの最適化
入力バウンドなパイプラインのボトルネックはタスクによって異なるので、プロファイラを使って検証すべき
- JAXならPerfetto、TensorFlow Profilerがある
- よくある原因
  - IO
  - データの前処理（事前にやっておくと良い）
  - マシン間の同期


## モデルの評価
バッチサイズを大きくする

## 最適なチェックポイントの選び方
retrospective optimal checkpoint selection
アーリーストッピングはしなくて良い

## 実験結果の記録
これらをメモしておく
- 実験の名前
- Configへのリンク
- 試行回数
- 最高の検証スコア
- 再現するためのコマンド
- 
## バッチ正規化
層正規化に置き換えることもよくあるが、置き換えられないときはバッチサイズやGPU数を変えるのに要注意
- 活性値の平均と分散はGPUごとに異なり、明示的に動悸されない限りは異なる値が保持される
- この値を計算するには64サンプルあれば十分

## マルチノード
バグが起きやすいので要注意！
- ログとチェックポイントは1つのノードだけでやる
- バッチ正規化が同期されている
- モデルの初期化のための乱数シードは全体で統一し、データのシャッフルや前処理の乱数シードは異なるものを使う
- データのファイルをシャードしておくと高速化できる

# FAQ
## スケジューリングはどれがいい？
最高のスケジューリングを決めるのは難しいが、何かしらは使ったほうが良い。いろいろな学習率を試すことで、モデルにとって最適な学習率に当たりやすくなる。linear decayやコサインをよく使うが、他のものでも良い。論文で見かける複雑なスケジューリングは、HIL的な手続きの結果であることもある。
## Adamのハイパラのチューニング方法は？
どこまでやるかは予算次第。10回未満で済ませるなら、学習率のみ。25回以下なら、β1も。それ以上なら、イプシロンも。もっと増やせるなら続いてβ2も。
## なぜ準ランダムな探索を推すのか？
チューニングのインサイトを得るためには（探索フェーズ）ベイズ最適化よりも適切。ランダムサーチよりもグリッドに近いため一様性が期待できる。検証エラーだけでなく訓練エラーも見たくなったときなど、後からの分析で使いやすい。統計的な再現性が高いなどのメリットが有る。
https://github.com/mlcommons/algorithmic-efficiency/blob/main/algorithmic_efficiency/halton.py
## 訓練がうまくいかないとき
不安定には2つの種類がある
- 初期
  - LRのウォームアップ（最適な学習率が、Feasibleのギリギリなとき）
    - unstableになる瞬間の10倍の学習率までウォームアップを入れる
    - どのくらいの長さでウォームアップをするかは、（10, 100, 1000, 10000）くらいのオーダーでチューニング
    - ウォームアップ後は一定の学習率で普通に学習できる
- 中盤で突然起きるもの
  - 勾配クリッピング
    - L2ノルムを監視してみる
    - 異常値が出るようだったらそこでクリップする（90%ileとか）
    - 安定化のために半分以上のステップでクリップが発生するなら、学習率を下げたほうがいい

正規化
Normalization should be the last operation before the residual. E.g. x + Norm(f(x)).
Norm(x + f(x)) known to cause issues.

学習率を下げるのは最後の手段

